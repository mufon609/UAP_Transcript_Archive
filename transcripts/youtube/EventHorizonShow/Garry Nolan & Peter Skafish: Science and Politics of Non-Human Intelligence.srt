1
00:00:00,000 --> 00:00:24,000
You have fallen into Event Horizon with John Michael Gaudier.

2
00:00:24,000 --> 00:00:28,000
Joining John today are doctors Gary Nolan and Peter Scafish.

3
00:00:28,000 --> 00:00:41,000
Dr Peter Scafish is a socio-cultural anthropologist who works between his discipline and philosophy on how ideas, cosmologies and translation shape the diversity of human thought and experience.

4
00:00:41,000 --> 00:00:55,000
He is currently engaged in research that employs anthropological perspectives on pluralism, cosmology, modernity and religion to anticipate how the sort of non-human beings that we imagine to design UAP might think

5
00:00:55,000 --> 00:01:01,000
and in what ways this thinking is likely to be both commensurate and incommensurate with our own.

6
00:01:01,000 --> 00:01:14,000
He is also developing his advisory research for Sol broad recommendations for genuinely democratic, whole of society approach to solving the legal, political and environmental problems raised by UAP.

7
00:01:14,000 --> 00:01:34,000
He has a PhD in anthropology from the University of California Berkeley and has held faculty and research positions in the United States, France, Canada and Germany, including at universities such as UC Berkeley, the CollÃ¨ge de France, McGill University and the Bauhaus University Weimar.

8
00:01:35,000 --> 00:01:44,000
Dr Nolan is the Rachford and Carlota A. Harris Professor in the Department of Pathology at Stanford University School of Medicine.

9
00:01:44,000 --> 00:01:55,000
He has published over 300 research articles and is the holder of 40 US patents and has been honoured as one of the top 25 inventors at Stanford University.

10
00:01:55,000 --> 00:02:07,000
His area of research includes hematopoiesis, cancer and leukemia, autoimmunity and inflammation and computational approaches for network and systems immunology.

11
00:02:07,000 --> 00:02:18,000
Dr Nolan's efforts are to enable a deeper understanding not only of normal immune function, trauma, pathogen infection and other inflammatory events.

12
00:02:18,000 --> 00:02:22,000
Remember to subscribe to Event Horizon so you never miss an episode.

13
00:02:25,000 --> 00:02:26,000
Welcome to the program.

14
00:02:26,000 --> 00:02:28,000
Thanks for having us.

15
00:02:28,000 --> 00:02:30,000
Yeah, thank you very much.

16
00:02:30,000 --> 00:02:34,000
Now, my first question I want to direct to Gary because we were talking about it off air.

17
00:02:34,000 --> 00:02:47,000
Scientists looking into the UAP phenomenon and people still sometimes scoff at it even though we have this mountain of governmental evidence that there is something going on here.

18
00:02:47,000 --> 00:02:48,000
There's a something here.

19
00:02:48,000 --> 00:02:53,000
What is your view and how have you navigated the sort of landscape of ridicule?

20
00:02:53,000 --> 00:03:00,000
Well, I think you start as with any scientific idea when it's first brought up and people might look askance at it.

21
00:03:00,000 --> 00:03:02,000
And so what do you do?

22
00:03:02,000 --> 00:03:05,000
You say to the I wouldn't even call them opposing party.

23
00:03:05,000 --> 00:03:10,000
I would say you say to the discussions at the table, what's the data?

24
00:03:10,000 --> 00:03:17,000
What is it that we have in front of us that tells us that there is actually something worth looking at?

25
00:03:17,000 --> 00:03:23,000
And I take a step back and say, how is it that a scientist approaches a problem in general?

26
00:03:23,000 --> 00:03:30,000
You look for something called preliminary data where there's enough evidence to suggest that there's something they're worth looking for.

27
00:03:30,000 --> 00:03:32,000
You don't jump to a conclusion.

28
00:03:32,000 --> 00:03:38,000
You say that here are the possible conclusions that might be on the table because of the data.

29
00:03:38,000 --> 00:03:47,000
You don't start by taking things off the table if the data says, well, the question is open enough that it's worth raising the following 10 questions.

30
00:03:47,000 --> 00:03:51,000
Now, scientists like humans are herd animals.

31
00:03:51,000 --> 00:03:59,000
And so much of the skepticism that I think you have out there in the world is because people are just following the herd.

32
00:03:59,000 --> 00:04:05,000
But like any good herd animal, somebody has to sense to call it the predator.

33
00:04:05,000 --> 00:04:14,000
And in this case, the predator is an idea that there might actually be something else out there that is outside of our normal range of considerations.

34
00:04:14,000 --> 00:04:18,000
And let's just say it right up UAP, whatever these phenomenon are.

35
00:04:18,000 --> 00:04:22,000
So somebody says, let's follow this up and get interested in it.

36
00:04:22,000 --> 00:04:31,000
Now, if you have the rest of the herd saying, don't follow the idea, then you're at risk of the predator doing something to you.

37
00:04:31,000 --> 00:04:43,000
Now, if you, though, can convince enough people that here's a credible way to talk about it, in this case, we're talking about then let's get right to the science of it is a credible way to talk about what if without coming to conclusions,

38
00:04:43,000 --> 00:04:51,000
you start to get more and more individuals involved, then that adds to the impetus that more people should pay attention.

39
00:04:51,000 --> 00:05:00,000
And I've had no problem over the last two or three years, especially with other scientists being interested in it and having very detailed discussions.

40
00:05:00,000 --> 00:05:10,000
And hundreds now of scientists wanting to get involved because they've now started to see the data and agree with me that there's something here worth following.

41
00:05:10,000 --> 00:05:14,000
Peter, your view from the point of anthropology.

42
00:05:14,000 --> 00:05:17,000
Well, yeah, I think how could I follow up on that?

43
00:05:17,000 --> 00:05:25,000
I think what Gary said about the herd mentality here is skepticism is is quite insightful.

44
00:05:25,000 --> 00:05:43,000
Well, what I would add to that is that, you know, the last 400 years of history from 17th century forward, which is how people like me and anthropology related fields define modernity, the cultural epic we live in that comes with a certain

45
00:05:43,000 --> 00:05:46,000
anthropocentric cosmology.

46
00:05:46,000 --> 00:05:57,000
That period of time has been defined by skepticism, because a certain level of skepticism was necessary to get the natural sciences as we know them today off the ground and running.

47
00:05:57,000 --> 00:06:11,000
And we owe a certain skeptical spirit to the philosopher Rene Descartes, who in a way embodied for us the idea that a truly insightful mind is going to be perceived primarily with skepticism.

48
00:06:11,000 --> 00:06:20,000
In the last four or five decades, social scientists and humanities scholars have called into question the usefulness of that level of skepticism.

49
00:06:20,000 --> 00:06:34,000
And we've certainly we've had precursors in philosophy doing that, like philosopher William James, who is interested in a variety of anomalous experience from religious experience to psychical phenomena to psychopathology.

50
00:06:34,000 --> 00:06:40,000
And the attitude we've taken is that skepticism erodes social trust.

51
00:06:40,000 --> 00:06:44,000
We don't trust each other and we don't trust what people think.

52
00:06:44,000 --> 00:06:46,000
We don't trust what people say.

53
00:06:46,000 --> 00:06:58,000
We even don't trust people's interest when they're engaged in intellectual and other kinds of inquiry, because we assume in advance that not only that they must be wrong, but that there are kind of liabilities for us.

54
00:06:58,000 --> 00:07:03,000
If we take on board some of their ideas and let them influence us.

55
00:07:03,000 --> 00:07:13,000
So I'd say there's a kind of psychological and social dimension, skepticism, just as Gary is, in which we become kind of phobic towards the other who thinks things that we're afraid of.

56
00:07:13,000 --> 00:07:23,000
And a lot of I think a lot of scientists like Gary and Gary has kind of phenomenal curiosity across domains recognize that this isn't healthy.

57
00:07:23,000 --> 00:07:43,000
And one thing I would say about this is we know from this philosopher I mentioned, William James, that often belief in a possibility makes for better science, better philosophical inquiry, better social science, because your belief that something might be the case actually motivates you to confirm it.

58
00:07:43,000 --> 00:07:55,000
Whereas people with low belief in a possibility tend not to be motivated to take the risk, the financial risk, the existential risk, the social risk to actually do very serious science and very serious inquiry.

59
00:07:55,000 --> 00:08:04,000
And Peter's perfectly right on that and made me think of something that I really hadn't before on this whole skepticism and how it drove literally the creation of science.

60
00:08:04,000 --> 00:08:17,000
I mean, before we had the kind of science that we think of as today, we had 100,000 theories about how the universe operated, everything from religious to shamanistic to mysticism, et cetera.

61
00:08:17,000 --> 00:08:29,000
And the idea of using skepticism and proof came along and said, let's just order the world according to a certain set of rules, or at least here's how we will discover what those rules are and what their validity is.

62
00:08:30,000 --> 00:08:45,000
But like everything, there's a pendulum. And as Peter, I think, is pointing out, the pendulum, at least in some instances in modern society, has moved too far to the overt antagonism to how new ideas might contribute.

63
00:08:45,000 --> 00:08:54,000
I mean, I never achieved anything in my laboratory or in the various companies and things that I've created by following the grain.

64
00:08:54,000 --> 00:09:00,000
It's always been people thought me at the beginning and now everybody uses the technology that we invented.

65
00:09:00,000 --> 00:09:12,000
So, you know, I think that and if you look at inventors and entrepreneurs and creators in either business or science or philosophy, it's always been ideas that went against the grain.

66
00:09:12,000 --> 00:09:16,000
And and yet they were the things that ended up changing the world.

67
00:09:17,000 --> 00:09:24,000
Now, one thing here, though, and it has to be noted, is that, look, there's not that much of a reason to be hyper skeptical anymore.

68
00:09:24,000 --> 00:09:36,000
We have a bunch of government action and problems that are becoming apparent within government that are showing that there is something here and there's a something here.

69
00:09:36,000 --> 00:09:42,000
And that's the thing is that it's not really that level of skepticism is not warranted by anything any longer.

70
00:09:42,000 --> 00:09:44,000
I don't think. What do you think?

71
00:09:44,000 --> 00:09:47,000
No, it's it's really not warranted by that.

72
00:09:47,000 --> 00:09:53,000
And I said, you know, interview recently for the Hill and I'll say it again.

73
00:09:53,000 --> 00:10:04,000
People should be extremely high confidence that there are genuine UAP vehicles, by which I mean, these are these are not vehicles made by human beings.

74
00:10:04,000 --> 00:10:13,000
We can call them non anthropogenic, and they should have that high level of confidence because we now have eight distinct pieces of legislation passed by Congress.

75
00:10:13,000 --> 00:10:25,000
Not stuff that's in draft, eight pieces of legislation, always sections generally the annual defense legislation that aren't just they don't just concern the vehicle.

76
00:10:25,000 --> 00:10:40,000
They concern Congress's interest in getting the bottom of what pockets of the intelligence community are in defense, probably the Department of Energy and also certain defense contractors know about these vehicles.

77
00:10:40,000 --> 00:10:54,000
What they know by detection and tracking, which is in the legislation, what they know from recovery of the vehicles following landings or crashes and also from the study of the vehicles once they've gotten their hands on them.

78
00:10:54,000 --> 00:11:00,000
And there's a lot of public discussion about that legislation that really comes at it from the wrong angle.

79
00:11:01,000 --> 00:11:27,000
You know, there's a kind of Reddit thread of discussion that suggests the legislation might be some kind of psychological or information operation against the American people, which is a pretty absurd possibility to entertain because you would have to think that Chuck Schumer, Kirsten Gillibrand, Marco Rubio were willing to sponsor basically fraudulent legislation that would put them in jeopardy with their constituencies.

80
00:11:27,000 --> 00:11:38,000
I suppose to kind of signal to the public or to China that certain technologies that belong to the US were somehow alien.

81
00:11:38,000 --> 00:11:40,000
That's very, very implausible.

82
00:11:40,000 --> 00:11:53,000
That legislation emanates from the committees in Congress that have access to the most sensitive classified information and the staff members and the congressional members of those committees.

83
00:11:53,000 --> 00:11:58,000
They know how to vet classified information. They know how to assess whether they're being spun.

84
00:11:58,000 --> 00:12:04,000
They know how to dialogue with people briefing them to make sure that they're really getting the kind of information they need.

85
00:12:04,000 --> 00:12:10,000
And that legislation is based on that kind of briefing, based on that kind of classified information.

86
00:12:10,000 --> 00:12:31,000
And I don't think anyone should have any doubt about the fact that good decisions were made within the Senate and also within the House to go ahead and start to have the legislative branch participate in decisions and activities taking place in other parts of federal government about UAP.

87
00:12:31,000 --> 00:12:42,000
Do you gentlemen think that we had the Schumer Amendment, but then there was a gutting of it and it sort of lost some of its teeth, though it had some pretty strong teeth initially.

88
00:12:42,000 --> 00:12:47,000
Do you think that affects it? Do you think it can still be effective once enacted?

89
00:12:47,000 --> 00:12:52,000
It could still be effective as far as enlightening us on what's going on here.

90
00:12:52,000 --> 00:12:58,000
I think the way that the new act is structured does put things behind the scenes again.

91
00:12:58,000 --> 00:13:12,000
But let's go back for your audience a little bit and list some of the things that were actually in that UAP Amendment that Schumer and Rounds put forward just so they understand the context of what was in it and what was lost.

92
00:13:12,000 --> 00:13:15,000
But lost doesn't mean forever. Let's just keep it at that.

93
00:13:15,000 --> 00:13:39,000
So the first was it was an all of government collection of the data and bringing it under the purview of a group of professionals that would include intelligence community, individuals, military, public individuals, laypeople, sociologists, ethicists, scientists, et cetera, who would look at the totality of it.

94
00:13:39,000 --> 00:13:47,000
They would, of course, have the necessary clearances to do so and would decide, OK, well, for good reason, this needs to stay secret.

95
00:13:47,000 --> 00:13:51,000
But for also good reason, this can now go into the public domain.

96
00:13:51,000 --> 00:14:01,000
And then there was a third arm that I had put forward, which was, well, it might be something that's not so secret, but might have material utility in the sciences.

97
00:14:01,000 --> 00:14:06,000
And perhaps there's an opportunity for public private investment to bring other scientists in.

98
00:14:06,000 --> 00:14:09,000
OK, so this circles back to what Peter just said.

99
00:14:09,000 --> 00:14:19,000
Why would the U.S. government, Congress, like 10 or 12 senators, a whole retinue of Congress people, put something like this together and allow it to go forward?

100
00:14:19,000 --> 00:14:23,000
OK, so it went forward. It went to committee.

101
00:14:23,000 --> 00:14:34,000
And then a couple of representatives, Republicans both, came out of the woodwork, had not been involved previously in any of the discussions in the write up of it and put enormous pressure.

102
00:14:34,000 --> 00:14:45,000
And as interestingly as well did some aeronautics companies, a lobbying group, come forward and put enormous pressure to have certain of the provisions removed.

103
00:14:45,000 --> 00:14:54,000
Well, what were those provisions? Well, one of them was the UAP committee to be, you know, oversight committee to be appointed by Biden and confirmed by the Senate.

104
00:14:54,000 --> 00:15:06,000
The other was to remove what was called the eminent domain provision, which would have given the government the right to seize materials being held allegedly by some of these contractors.

105
00:15:06,000 --> 00:15:15,000
So why would two Republican, one was the head of the Senate Intelligence Committee, sorry, the Congressional Senate, and the other was Armed Services.

106
00:15:15,000 --> 00:15:16,000
House Intelligence Committee.

107
00:15:16,000 --> 00:15:18,000
House Intelligence, sorry, thank you.

108
00:15:18,000 --> 00:15:23,000
Why would they spend so much time and effort to gut something that didn't exist in the first place?

109
00:15:23,000 --> 00:15:31,000
So I asked critics who you mentioned in the run up before we were to the program who had skepticism and saying, well, you're going to ruin the reputation of your program.

110
00:15:31,000 --> 00:15:40,000
I challenged them, first of all, to reach out to me and talk to me and see if I think my reputation has been ruined or I would ruin anybody's reputation myself or Stanford as well.

111
00:15:40,000 --> 00:15:48,000
But I challenged them to go in and look at that and be ready for me to challenge their knowledge of the subject.

112
00:15:48,000 --> 00:15:52,000
And if they don't have any knowledge of the subject, I would demand a retraction.

113
00:15:52,000 --> 00:15:53,000
That's a common theme.

114
00:15:53,000 --> 00:15:57,000
You know, you find that usually more often than not, they haven't gone down the rabbit hole.

115
00:15:57,000 --> 00:15:58,000
Exactly.

116
00:15:58,000 --> 00:16:03,000
And you don't have to be, look, I'm skeptical of a lot of the things that I hear.

117
00:16:03,000 --> 00:16:04,000
Absolutely.

118
00:16:04,000 --> 00:16:06,000
And I hold it all in abeyance.

119
00:16:07,000 --> 00:16:23,000
I hold all of it in, you know, in a quantum reality of I'm waiting for the deciding data factoid to let it all to collapse into some set of truths.

120
00:16:23,000 --> 00:16:35,000
But the best scientists, the best thinkers are able to do that to keep all things juggled until the moment of truth that allows you to put the whole thing together.

121
00:16:35,000 --> 00:16:37,000
Yeah, that's quite well said, Gary.

122
00:16:37,000 --> 00:16:48,000
And to kind of follow up, to bring it back to some of the scientific questions as we discuss the political ones is, you know, there's a misperception among people, not only skeptics,

123
00:16:48,000 --> 00:17:04,000
but people are confused about this, about academics like us, government people like us who were engaged with the subject and really devoting a lot of daily hours to it professionally that we believe we understand a lot about this.

124
00:17:04,000 --> 00:17:14,000
You know, Gary's known for a long time, and I've known for a couple years now, a lot of the best people coming out of government on this and a lot of the best scientists who kind of run with them.

125
00:17:14,000 --> 00:17:25,000
And among this network, and I'll include myself in it now, we don't think we know much at all, right down to the question of whether these things are extraterrestrial or something else.

126
00:17:25,000 --> 00:17:30,000
The thing people are most confident about is that there is technology there.

127
00:17:30,000 --> 00:17:39,000
There's a kind of vehicle there, but there's a lot of, the rest of it is many possibilities, and Gary put it pretty well.

128
00:17:39,000 --> 00:17:47,000
They stay in a kind of virtual state of superposition for us where we're entertaining all of them at once and committing to almost none of them.

129
00:17:47,000 --> 00:17:56,000
Even if we have an inkling that a few might be correct to the exclusion of others, once things come out of superposition, so to speak.

130
00:17:56,000 --> 00:18:06,000
And discovering that, as I've interacted with government people and scientists on this who have been working on this for years,

131
00:18:06,000 --> 00:18:16,000
actually gave me a lot of confidence that I was on the right track with this because I found that I was in very serious intellectual company,

132
00:18:16,000 --> 00:18:23,000
very serious scientific company, very serious thinking company, because I wasn't dealing with weak minds.

133
00:18:23,000 --> 00:18:27,000
I've met some of the strongest minds I've known in this field.

134
00:18:27,000 --> 00:18:36,000
Very strong empiricists, very strong theoreticians, and truly curious minds, some of whom are absolutely formidable.

135
00:18:36,000 --> 00:18:39,000
But I think the question is, what are the critics afraid of?

136
00:18:39,000 --> 00:18:43,000
I mean, really, it's why are you afraid to talk about it?

137
00:18:43,000 --> 00:18:46,000
And why do you care what I think?

138
00:18:46,000 --> 00:18:49,000
And why do you care that I think the way I do?

139
00:18:49,000 --> 00:18:59,000
They need to look, they need to pick up a mirror and look at it and say, why does it bother you to even entertain the possibility?

140
00:18:59,000 --> 00:19:05,000
And if you're not willing to look into the raw data, then step aside and let somebody else do it.

141
00:19:05,000 --> 00:19:07,000
As simple as that.

142
00:19:07,000 --> 00:19:08,000
Yeah, I agree.

143
00:19:08,000 --> 00:19:11,000
And personally, I like entertaining the possibilities.

144
00:19:11,000 --> 00:19:18,000
That's where anything interesting in life happens, is when you entertain alternate possibilities to challenge your own beliefs,

145
00:19:18,000 --> 00:19:21,000
and then you get to know what your beliefs actually are.

146
00:19:21,000 --> 00:19:26,000
And that to me has been the most useful exercise in the whole UAP phenomenon, following it for years now,

147
00:19:27,000 --> 00:19:31,000
is that it does challenge my scientific thinking, but at the same time, I can't tell you why.

148
00:19:31,000 --> 00:19:39,000
So there just doesn't seem to be any reason, especially when you have a bipartisan effort like this in Congress.

149
00:19:39,000 --> 00:19:47,000
And that's a very important word, bipartisan, with the exception of the two opposing senators that oppose the Schumer Amendment for whatever reason.

150
00:19:47,000 --> 00:19:50,000
But everybody seemed to be on the same page.

151
00:19:50,000 --> 00:19:54,000
You can find, you know, Moskowitz or plenty of Republicans per chat.

152
00:19:54,000 --> 00:20:03,000
So half of the government seems to agree, but there does seem to be some contingent within it that doesn't agree and doesn't want this out there.

153
00:20:03,000 --> 00:20:06,000
So my question for you, Peter, is this, what do we do?

154
00:20:06,000 --> 00:20:14,000
How do we get the government to take a look internally at itself and try to weed out what the problem is here?

155
00:20:15,000 --> 00:20:25,000
Well, OK, my current view on this, and this is something I'm really devoting time to in 2024, both in terms of advocacy and in writing,

156
00:20:25,000 --> 00:20:30,000
is I think it falls to Congress right now to make that happen.

157
00:20:30,000 --> 00:20:39,000
And that's first and foremost because any activity that exists within government, historically, has been within the executive branch.

158
00:20:39,000 --> 00:20:47,000
And without pointing the finger or condemning, we can start simply by saying branches of government tend not to reform themselves.

159
00:20:47,000 --> 00:20:51,000
This is what checks and balances are about in the American system.

160
00:20:51,000 --> 00:20:56,000
And, you know, there are times executive branch has to push the legislative on certain things.

161
00:20:56,000 --> 00:21:02,000
In this case, the legislative really has to push the executive on this because with the Schumer Amendment, in a way,

162
00:21:02,000 --> 00:21:09,000
they just gave the executive the opportunity to drive and control the review process.

163
00:21:09,000 --> 00:21:16,000
The panel, the Schumer Amendment, the declassification review panel, the Schumer Amendment was to create,

164
00:21:16,000 --> 00:21:22,000
was to operate on behalf of the president and report to some extent to Congress.

165
00:21:22,000 --> 00:21:28,000
Without that there, I think Congress made a fairly diplomatic and polite gesture on that point.

166
00:21:28,000 --> 00:21:32,000
And we're trying to work very constructively with the administration.

167
00:21:32,000 --> 00:21:40,000
I think now the ball goes back to Congress, and Congress has to make its own decisions about how it's going to do this.

168
00:21:40,000 --> 00:21:47,000
Without real assistance from the executive outside all-domain Anomaly and Resolution Office,

169
00:21:47,000 --> 00:21:50,000
which hasn't been used for some time, they're going to have to make that decision.

170
00:21:50,000 --> 00:21:52,000
And they're probably going to have to resort.

171
00:21:53,000 --> 00:21:58,000
And this is, you know, the talk of House right now, House Oversight Committee.

172
00:21:58,000 --> 00:22:01,000
They're going to have to resort to some kind of investigation.

173
00:22:01,000 --> 00:22:06,000
To conduct such an investigation, they're going to need partners in the executive branch for sure,

174
00:22:06,000 --> 00:22:11,000
but they're also going to have to proceed with the attitude that they're going to have to push,

175
00:22:11,000 --> 00:22:15,000
they're going to have to show they mean it, and they're going to have to say,

176
00:22:15,000 --> 00:22:22,000
Fundamentally, you know, we should have never been cut out of this as a domain of knowledge and activity

177
00:22:22,000 --> 00:22:24,000
within the executive branch of the U.S. government.

178
00:22:24,000 --> 00:22:32,000
We had every right to participate in decisions about this, to legislate about it, to have oversight over it.

179
00:22:32,000 --> 00:22:37,000
And yet that never happened from the 1940s, 50s forward.

180
00:22:37,000 --> 00:22:43,000
We've only had a kind of very minimal beginning of oversight in the last few years.

181
00:22:43,000 --> 00:22:49,000
It's fairly neat, given the amount of activity that's probably there historically.

182
00:22:49,000 --> 00:22:54,000
And I think you saw something happen just in the last couple of days, to Peter's point,

183
00:22:54,000 --> 00:23:02,000
where members of the House had a meeting with the Inspector General of the Intelligence Communities,

184
00:23:02,000 --> 00:23:05,000
primarily about David Grish's claims.

185
00:23:05,000 --> 00:23:09,000
And all the main members who'd been at the original hearing were there,

186
00:23:09,000 --> 00:23:16,000
and then, perhaps surprisingly, two individuals, the two representatives who came out against the amendment,

187
00:23:16,000 --> 00:23:22,000
Turner and Rogers, they showed up as well at a meeting for something that wasn't supposed to exist.

188
00:23:22,000 --> 00:23:25,000
And that surprised everybody that they showed up.

189
00:23:25,000 --> 00:23:33,000
To a one of them, they came out very stone-faced, and several of them came up to the reporters who were on hand

190
00:23:33,000 --> 00:23:38,000
and basically said, there's something here, and we need to follow up on this.

191
00:23:38,000 --> 00:23:41,000
And all of the things that Peter just said about representative of government.

192
00:23:41,000 --> 00:23:44,000
But one of them especially struck me, and he came out and he goes,

193
00:23:44,000 --> 00:23:52,000
what this told me was what everybody has feared, that the American people are being kept out of something

194
00:23:52,000 --> 00:23:56,000
and that there's a concerted effort to stop them from knowing about it.

195
00:23:56,000 --> 00:24:00,000
So, you know, the old adage, where there's smoke, there's fire.

196
00:24:00,000 --> 00:24:03,000
What is it that needs to be understood here?

197
00:24:03,000 --> 00:24:06,000
Oh, and the other main point that came across from all of them was,

198
00:24:06,000 --> 00:24:13,000
from what we heard, what David Grush said, and we heard this directly from the ICIG, he was credible.

199
00:24:13,000 --> 00:24:18,000
And I just read something recently, they said, and we know where the programs are.

200
00:24:18,000 --> 00:24:21,000
It was literally just on Twitter this morning.

201
00:24:21,000 --> 00:24:23,000
We now know where the programs are.

202
00:24:23,000 --> 00:24:30,000
So, put that in the hopper, skeptics, and chew on it, and let's see what you have to say after that.

203
00:24:31,000 --> 00:24:38,000
Peter, my question for you, again, in the perspective of anthropology is, all right, so we get the goods.

204
00:24:38,000 --> 00:24:42,000
And this has been a secret that's been held for 70 years.

205
00:24:42,000 --> 00:24:47,000
And then the misdirection and some people, you know, their claims of very dark stuff,

206
00:24:47,000 --> 00:24:50,000
very dark stuff in the history of this subject.

207
00:24:50,000 --> 00:24:52,000
And that all comes out.

208
00:24:52,000 --> 00:24:58,000
And we find out that the CIA or somebody is misbehaving like they have in the past.

209
00:24:59,000 --> 00:25:06,000
What happens to American society and global societies if this kind of information comes out

210
00:25:06,000 --> 00:25:10,000
that there's something happening that we don't really understand?

211
00:25:10,000 --> 00:25:16,000
Well, you know, first, there was the problem for US government and also social bonds in the United States

212
00:25:16,000 --> 00:25:20,000
at a time when there's very low trust in government.

213
00:25:20,000 --> 00:25:25,000
There's very low trust between different social groups and collectives in the United States.

214
00:25:25,000 --> 00:25:30,000
There's increasing skepticism, I say in quotations, directed against science of all things.

215
00:25:30,000 --> 00:25:37,000
And, you know, so this has to be dealt with very responsibly, very carefully, because, you know,

216
00:25:37,000 --> 00:25:44,000
as someone on Capitol Hill said to Gary and I once in person during a meeting we had there,

217
00:25:44,000 --> 00:25:51,000
in a way, this person said, we're giving to the American people the ultimate conspiracy theory, and yet it's true.

218
00:25:51,000 --> 00:25:59,000
And I think, you know, I've had activist friends say the amount of outrage there will be among people

219
00:25:59,000 --> 00:26:07,000
who aren't willing to be diplomatic about this is going to be massive, because this is such a significant fact.

220
00:26:07,000 --> 00:26:15,000
And the secrecy was so total, so blanket, and so successful that the feeling people are going to have

221
00:26:16,000 --> 00:26:24,000
about being lied to about this, and it was a lie at different times, an explicit lie, it wasn't just misdirection, is going to be terrible.

222
00:26:24,000 --> 00:26:34,000
So I think this has to be managed in a very cautious spirit and with a sense that it's not going to be good for anybody

223
00:26:34,000 --> 00:26:42,000
if there's too much accusation, if there's too much blaming, and if there's too much of a desire to see heads roll.

224
00:26:42,000 --> 00:26:49,000
You know, we don't want the guillotine for this. We don't even want too many indictments in prison.

225
00:26:49,000 --> 00:26:55,000
I think we need to have a reckoning, a big social reckoning, but it needs to be done in a way that is much more about

226
00:26:55,000 --> 00:27:02,000
getting access to truth than it is about trying to prosecute people.

227
00:27:02,000 --> 00:27:08,000
And I'm not trying to say that Congress shouldn't have an interest in that or that law enforcement shouldn't have an interest in that,

228
00:27:08,000 --> 00:27:16,000
but I think the emphasis needs to just be about informing people and really going into discovering what the real reasons were

229
00:27:16,000 --> 00:27:22,000
at different points in U.S. history for beginning the secrecy and maintaining the secrecy.

230
00:27:22,000 --> 00:27:28,000
I don't think that was all irresponsible, but I think that as the secrecy continued in its blanket fashion,

231
00:27:28,000 --> 00:27:33,000
certainly there was some irresponsibility because it went on for too long, it was too total,

232
00:27:33,000 --> 00:27:39,000
and it really, I think, has created a distorted sense of who, you know,

233
00:27:39,000 --> 00:27:48,000
we barely can estimate the damage that it's done to ourselves as human beings in our self-understanding.

234
00:27:48,000 --> 00:27:56,000
They've had a secret kept in this way that might have enlightened us, that would have enlightened us inevitably about who we are,

235
00:27:56,000 --> 00:28:01,000
what we are, and I won't even say what our place in the universe is, but what the universe is at all,

236
00:28:01,000 --> 00:28:13,000
because I think it will cause us to reframe our understanding of that and eventually to see a new scientific facts about what we call the universe today.

237
00:28:13,000 --> 00:28:19,000
And that's one of the things that brought Peter and I together to create the Soul Foundation,

238
00:28:19,000 --> 00:28:26,000
which was to basically put these things in context for government and for commercial entities

239
00:28:26,000 --> 00:28:34,000
and to basically provide them the reasoning that Peter just went through from a historical or sociological point of view,

240
00:28:34,000 --> 00:28:43,000
and to be there as an outside academic advisory group to provide information to government agencies about how to approach it,

241
00:28:43,000 --> 00:28:51,000
to write the white papers about what the context is, what's the history, what were the perhaps original reasons why this all came to be,

242
00:28:52,000 --> 00:29:00,000
and then what are the proofs. And to do it in a way, and this circles all the way back to the whole idea of skepticism and scientific proof and discussion,

243
00:29:00,000 --> 00:29:09,000
and to provide the paper trail in the public record and the public realm that allows other scientists to approach it and say,

244
00:29:09,000 --> 00:29:20,000
OK, well, here's a non tinfoil hat approach to this that reasons all of this out in a parlance and a language that I understand.

245
00:29:20,000 --> 00:29:27,000
And Peter has a parlance and an audience in his academic realm that's different than mine,

246
00:29:27,000 --> 00:29:35,000
which is why having these two kinds of disciplines together in one organization, the Soul Foundation, really matters.

247
00:29:36,000 --> 00:29:43,000
It is of the utmost importance to have cross-disciplinary talk, talk to the astrophysicist, talk to, which I know you do,

248
00:29:43,000 --> 00:29:48,000
and get everybody involved, and from your background, Gary, with medical science.

249
00:29:48,000 --> 00:29:54,000
There are all kinds of things in material science that could be done that puts everybody's heads together.

250
00:29:54,000 --> 00:30:02,000
Let me ask you this, though, gentlemen. Would the next step, would it be helpful if Congress had subpoena power,

251
00:30:02,000 --> 00:30:11,000
teeth, and a general amnesty to offer anybody in government a way out to just disclose it, at least internally to Congress?

252
00:30:11,000 --> 00:30:14,000
Well, the whistleblower law is already there. Go ahead, Peter.

253
00:30:14,000 --> 00:30:20,000
Yeah, I want to take that because you probably don't need subpoena power initially.

254
00:30:20,000 --> 00:30:28,000
There are other ways to conduct investigation in Congress that, you know, it doesn't involve the prospect of prosecution.

255
00:30:28,000 --> 00:30:37,000
It's much more about securing cooperation with certain witnesses, people in certain agencies, and Congress saying,

256
00:30:37,000 --> 00:30:44,000
look, we're being conciliatory, we're being diplomatic, but we want you to come in and tell us exactly what's going on

257
00:30:44,000 --> 00:30:51,000
and to do it to the right committees, the right environments where they have access to classified information.

258
00:30:51,000 --> 00:31:00,000
But we also want you to say it in public in such a way that people can understand in simple terms what's happened and what's true.

259
00:31:00,000 --> 00:31:04,000
In an interview I did the other day, one of the people in the interview said, you know,

260
00:31:04,000 --> 00:31:12,000
generally the public doesn't care about the arcana of classified programs and the details of budgets

261
00:31:12,000 --> 00:31:18,000
and which military base might be housing which piece of technology and so on.

262
00:31:18,000 --> 00:31:25,000
They want to know basic facts like, you know, look, OK, are these vehicles real? What do you know about them?

263
00:31:25,000 --> 00:31:33,000
Is there some, you know, is there a biological dimension to whatever might be on board the vehicle?

264
00:31:33,000 --> 00:31:37,000
Is there not? Is there safety here? Is there not?

265
00:31:37,000 --> 00:31:43,000
You know, very simple, basic question that I think could be answered in an open environment.

266
00:31:43,000 --> 00:31:46,000
And I think that's what needs to happen.

267
00:31:46,000 --> 00:31:49,000
The Seoul Foundation and a recent conference.

268
00:31:49,000 --> 00:31:53,000
How did things go and gentlemen, what was your takeaway as the founders?

269
00:31:53,000 --> 00:31:56,000
What was your takeaway from the speakers?

270
00:31:56,000 --> 00:32:03,000
Well, personally, I learned a lot, especially in the non-science context about how other frames of reference

271
00:32:03,000 --> 00:32:10,000
and academics can approach the problem and talk about it in different ways, religion being one of them especially.

272
00:32:10,000 --> 00:32:15,000
There was a military IC sort of government component to the conference as well.

273
00:32:15,000 --> 00:32:24,000
I mean, Carl Nell, the framer essentially of the UAP amendment was there and gave a rundown for the whys and wherefores

274
00:32:24,000 --> 00:32:28,000
of all of why certain things were put in and why they are important.

275
00:32:28,000 --> 00:32:33,000
And all of those videos, thankfully, will hopefully soon be up for everybody to view.

276
00:32:33,000 --> 00:32:39,000
And again, I had to ask our skeptical friends out there to take a look at them and see what they think.

277
00:32:39,000 --> 00:32:46,000
But I think the uniform feedback that we got and I think Peter and I were both surprised

278
00:32:46,000 --> 00:32:54,000
because we were so in the middle of putting it all together was how much people really enjoyed it and felt it was historic

279
00:32:54,000 --> 00:33:00,000
that they could actually have these kinds of conversations on the Stanford University campus

280
00:33:00,000 --> 00:33:06,000
and the engineering quad sponsored by Stanford and approved by Stanford

281
00:33:06,000 --> 00:33:11,000
because Stanford is all about the open inquiry. They've never stopped me from doing anything.

282
00:33:11,000 --> 00:33:16,000
They actually encouraged me to do it. So I was thrilled with the feedback.

283
00:33:16,000 --> 00:33:19,000
I was exhausted afterwards, but I was thrilled. Peter, go ahead.

284
00:33:19,000 --> 00:33:20,000
Peter, your thoughts?

285
00:33:20,000 --> 00:33:31,000
Well, I think our symposium, yeah, we got universally not just positive but enthusiastic feedback about that.

286
00:33:31,000 --> 00:33:37,000
And I think a lot of that came from professionals in a variety of fields.

287
00:33:37,000 --> 00:33:42,000
And I mean, a wide variety. We had venture capitalists there. We had people in the defense industry.

288
00:33:42,000 --> 00:33:49,000
We had artists and creative writers. We had scientists, of course.

289
00:33:49,000 --> 00:33:57,000
We had humanities people. We had people from government. We really had a wide gamut of people there.

290
00:33:57,000 --> 00:34:06,000
And the enthusiasm they expressed about the event really had to do with the fact that we created very professional discourse.

291
00:34:06,000 --> 00:34:12,000
And on top of that, we brought in people that in different ways are all doing very innovative work.

292
00:34:12,000 --> 00:34:16,000
I mean, Carl Nell took a very inventive approach to that legislation.

293
00:34:16,000 --> 00:34:20,000
I mean, it was in a way it was a perfect piece of legislation.

294
00:34:20,000 --> 00:34:31,000
And he was able to show how he thought very systematically about what needed to take place if there was going to be responsible disclosure on the part of the United States government.

295
00:34:31,000 --> 00:34:41,000
We have we had other scientists there that have utterly unique approaches to UAP, which don't start from traditional UAP data.

296
00:34:41,000 --> 00:34:51,000
They start, for instance, with astronomical images, which show transient objects, which may very well be as we understand them.

297
00:34:51,000 --> 00:35:07,000
So it was the quality of professional discourse, but also the fact that we brought in really, really inventive people on this and maintained a very high bar with with the people we chose and also the kind of discussion we had.

298
00:35:07,000 --> 00:35:11,000
And I don't think that's been done in exactly that way.

299
00:35:11,000 --> 00:35:13,000
There are groups that are doing it.

300
00:35:13,000 --> 00:35:19,000
But let's say without the same level, probably conviction and shared focus.

301
00:35:19,000 --> 00:35:21,000
Future conferences. Will there be more?

302
00:35:21,000 --> 00:35:24,000
Yes, we're actually literally this morning.

303
00:35:24,000 --> 00:35:35,000
Peter and I were in a group discussion about having more one large conference, certainly again this year, and perhaps some smaller summit conferences as well.

304
00:35:35,000 --> 00:35:38,000
Timing and nature of them still to be determined.

305
00:35:38,000 --> 00:35:45,000
A powerful case for why anthropology should study outsiders of thought and their speculative ideas.

306
00:35:45,000 --> 00:35:58,000
Dr. Peter Skafish's book, Rough Metaphysics, the speculative thought and mediumship of Jane Roberts, is now offered to Event Horizon viewers with a 40% off discount code.

307
00:35:58,000 --> 00:36:10,000
Use the link in the description or in the pinned comment below and use the discount code MN91060, which is good all the way through to February 29, 2024.

308
00:36:11,000 --> 00:36:18,000
Catastrophic disclosure, where whatever is disclosed is dangerous in some way.

309
00:36:18,000 --> 00:36:24,000
What are your guys' view on this idea of catastrophic disclosure that's been floating around as of late?

310
00:36:24,000 --> 00:36:36,000
I'd like to answer that because I think that the fact that the Schumer Amendment was gutted, it actually, you know, the folks that were intent on doing that.

311
00:36:36,000 --> 00:36:44,000
I'm not talking about this, who were intent on doing that, about the big provisions, maybe not some small provisions like eminent domain clauses that were in there.

312
00:36:44,000 --> 00:36:54,000
But in fact, who really didn't want the review of classified records to take place and to result in some kind of controlled public disclosure.

313
00:36:54,000 --> 00:37:04,000
I think they brought us to a situation where we're going to see uncontrolled and potentially catastrophic disclosure, catastrophic in the etymological sense.

314
00:37:04,000 --> 00:37:10,000
It will be an overturning order. It may happen very suddenly.

315
00:37:10,000 --> 00:37:21,000
I think that, you know, the disclosure we had in 2024, excuse me, 2023, was to some extent uncontrolled disclosure.

316
00:37:21,000 --> 00:37:32,000
It was done legally. It was done through a process that would be considered responsible by people coming out of the military and the intelligence community who have security clearances.

317
00:37:32,000 --> 00:37:40,000
But it was not directed by any government agency or Congress or the office of the president.

318
00:37:40,000 --> 00:37:47,000
I'm speaking of Dick Gresh's public testimony about his whistleblowing activity. That was disclosure.

319
00:37:48,000 --> 00:37:51,000
And part of Congress got it quite right.

320
00:37:51,000 --> 00:38:06,000
They got it exactly right by understanding that this was not just a credible set of claims on his part, but they were accurate and they needed to pay attention precisely because there's a democratic politics at stake.

321
00:38:06,000 --> 00:38:27,000
And what I would say is that if the whistleblowers, future whistleblowers, should they come forward, are not supported, if Congress is not supported by the executive in its desire to create transparency, openness, decrease secrecy, you're going to see more of that.

322
00:38:27,000 --> 00:38:32,000
And you're going to see the version potentially that would be something like civil disobedience.

323
00:38:32,000 --> 00:38:41,000
Now, I'm not advocating for that publicly. We haven't seen an Edward Snowden figure on UAP, classified UAP data yet.

324
00:38:41,000 --> 00:39:01,000
Should that person come along, that would be something like catastrophic disclosure, because suddenly, if there was something like a document done, if there was suddenly someone out in public who could attest to their credentials, who was able to provide verifiable information, things that are being kept secret in the UAP domain,

325
00:39:01,000 --> 00:39:09,000
every investigative journalist would suddenly realize it was accurate and it would be a complete scandal in the press.

326
00:39:09,000 --> 00:39:22,000
And the political fallout from that would be quite extreme. It would force a statement from whoever the sitting president is. It would force a lot of scrambling across executive branch agencies.

327
00:39:22,000 --> 00:39:38,000
There would be a lot of cleanup, just as there was with Edward Snowden. It would damage, let's say, I'm not advocating for thinking on these terms, but it would damage U.S. national security.

328
00:39:38,000 --> 00:39:52,000
These are serious equities the U.S. government has in these technologies, and they, by their own logic, they're right to keep them secret and right to be very careful about what might be told about them to the public.

329
00:39:52,000 --> 00:40:11,000
So that's a real possibility right now, and I think that those people and groups within the executive and defense contractors who think you can just keep this bottled up are probably playing with fire right now, and the fire will affect federal government.

330
00:40:11,000 --> 00:40:31,000
Nobody needs that right now. So I think we have to encourage cooperation between the executive and the legislative and also the contractors and try to bring them together into a productive dialogue in which it's possible to say, look, nobody wants crisis from the U.S.

331
00:40:31,000 --> 00:40:49,000
government, where suddenly you've got uncontrolled leaking and the recognition by the press that it's real, and you're forcing a president not only to have to speak to this, but I would say also to be then left holding the bag, which no administration wants to do with this if you've had generations of secrecy.

332
00:40:49,000 --> 00:41:03,000
So I think it's a very real prospect, and I think it's something that everyone is concerned about that should be working constructively to prevent, and I would additionally say we could go into it if you want, the social consequences.

333
00:41:03,000 --> 00:41:15,000
I don't think most people have really reflected on them. It sounds like a kind of Hollywood movie cliche, but markets could be affected, international relations could be affected.

334
00:41:15,000 --> 00:41:41,000
Even disclosure as it's happened so far, or government acknowledgments as they've happened so far, have likely been read by China as messages of some kind, even if they're not, or as indication that maybe the U.S. has had some kind of technological breakthrough, whether they've had it or not, that's being concealed by trying to misdirect adversaries by suggesting that U.S. experimental or

335
00:41:41,000 --> 00:42:01,000
classified technology that's operational already is actually UAP vehicles. So the social and international consequences are very, very serious, and people should take that seriously and not be hoping that this goes too fast.

336
00:42:01,000 --> 00:42:15,000
It would be a great situation if an administration, Congress, could come to a constructive agreement about how to do this in a paced way that wouldn't lead to a situation that they couldn't handle.

337
00:42:15,000 --> 00:42:37,000
Yeah, what Peter is calling out is the counterpoint to catastrophic disclosure. Catastrophic disclosure doesn't mean the world is going to end. It means we don't understand all of the consequences of how the information might suddenly, if released, change markets, change social dynamics, society, politics, etc.

338
00:42:37,000 --> 00:42:56,000
The counterpoint to catastrophic is controlled. Controlled disclosure is really what the UAP amendment, and I think it's follow-ons that will be put forward, we're meant to cover, is to prepare the levers and mechanisms of society to what's coming.

339
00:42:56,000 --> 00:43:09,000
Let's just put one example out on the table, even though it's almost perhaps the most far-fetched. Something like a way to change how we utilize gravity, or a way to change how we utilize energy.

340
00:43:09,000 --> 00:43:27,000
Those could be catastrophic to the current infrastructure of how the planet operates, as opposed to controlled, which would be, let's let out a little piece of the technology that we can attempt to understand that might change our fundamental understanding of how materials operate.

341
00:43:27,000 --> 00:43:41,000
Look for example, and I've used this example before, of how a grain of silicon, a grain of sand, germanium, changed all of human society. It created the computer chips and the artificial intelligence of today.

342
00:43:41,000 --> 00:44:04,000
Simple, tiny grain of sand, and how you dope it with contaminants, as it was called at the time. And that understanding changed everything. So imagine that if these vehicles, for me it's more than if, but I'll just keep it in the scientific realm, if these vehicles are operating with principles we don't understand, it's not magic, we just don't understand the physics right now.

343
00:44:04,000 --> 00:44:25,000
Plenty of stuff we don't understand about physics. What one minor understanding of the hundreds of technology revolutions that it took to get there could do to us. That's controlled use of the disclosure process, as opposed to uncontrolled, where everything is, nobody knows where anything is going, and markets hate unpredictability.

344
00:44:25,000 --> 00:44:45,000
Billions of dollars. Now I have been privy to data ostensibly allegedly produced on the study of some of the materials. And if one of my graduate students came to me with that kind of data or report, I would put them up for review as to whether their PhD candidacy should go forward.

345
00:44:45,000 --> 00:45:00,000
And what I'm saying in that is that what's happening is that the kinds of science that need to be done are not being done, and it's not that people don't have the best intention to do it, it's just that they don't have the scientific method at heart.

346
00:45:00,000 --> 00:45:14,000
Right? They collect the information, they put it in a report, and nobody looks at it and says, well, was this done the right way? Do we have the right controls? And almost more important, how can we use it?

347
00:45:14,000 --> 00:45:32,000
I mean, that to me is sort of the whole reason that the public funds science is not to satisfy my personal curiosity. It's to say, okay, Gary, we're going to use your curiosity to get something done.

348
00:45:32,000 --> 00:45:45,000
But remember in the back of your head that that's always the reason why we're giving you the money. And that's the difference between, I think, the kind of data that I've seen versus the kind of data and how to use it and how it can be done.

349
00:45:45,000 --> 00:46:08,000
Still, though, if you could figure out anything regarding the materials or whatever, you know, of a recovered UAP, that's very valuable, if you can figure it out. And do you think that the simple reason for all the secrecy and hyper classification is simply that we haven't figured it out? And we know that if we do, it would be amazingly useful.

350
00:46:08,000 --> 00:46:24,000
Nobody can know. I mean, if I operated my lab the way that these SAPs, these special access programs work, I would get nothing done. My lab works in a very, let's say, open network where everybody's project is slightly dependent on the knowledge that's created in another.

351
00:46:24,000 --> 00:46:53,600
And I never create, I never allow for anybody to be, I let leaders happen by how they use their data and how they share it. And that creates the kind of environment that pushes science forward in the best possible way. It incentivizes leaders to become leaders. And it incentivizes people to follow the data, because the data produces the papers that pushes their careers forward. And my students have spun out, I don't know, kind of how many companies out of my lab because of that.

352
00:46:53,600 --> 00:47:01,000
That's benefited society. And that's what I want to see happen here. And that's what I think can happen. But I just don't think it's structured in the right way.

353
00:47:04,160 --> 00:47:11,680
Do you think it's a overcompartmentalization problem in that they've compartmentalized it so much that nobody can look? You know, nobody?

354
00:47:11,800 --> 00:47:39,360
Yeah, John, I would follow up on Gary, Gary's point on this by engaging a little bit of sociological speculation, but I mean, kind of rigorous and insightful speculation. You know, our colleague and Gary's mentor, the French information scientist, anthropologist Jacques Ballet made a very remarkable and I think insightful observation.

355
00:47:40,000 --> 00:48:06,120
And one of his classic books on the subject where he said, look, there's there is a government cover up. But the cover up has another dimension, which is that we cover up our encounter with the phenomena from ourselves. There's a kind of unconscious repression or a kind of collective psychological dissociation, which we deny that there's something there.

356
00:48:07,000 --> 00:48:22,080
And we deny to ourselves that we know something about it, or we've experienced it. And if you look at the way, if you look at the allegations that come from, they brush or others, because he's not the first person who said that.

357
00:48:23,080 --> 00:48:39,600
We've had some other witnesses who have been pretty public about this, saying that we have very extreme compartmentalization. It's activities or pseudo programs being hidden within programs and kept in private industry so that you minimize reporting requirements.

358
00:48:39,600 --> 00:49:08,120
If you look at that as what's taking place with something as profound as this, as something as exciting as this and something as dangerous as this, and then you try to square it with the fact that you have to have agency directors in the intelligence community, secretaries of defense, very high military intelligence officials, all the way up to the National Security Council and probably historically present.

359
00:49:10,600 --> 00:49:33,120
Being cognizant of this stuff, then you realize that there has to be some kind of deep denial and repression going on collectively about this, because if you were really facing facts about this, you wouldn't compartmentalize it this way. You wouldn't devote the sorts of resources that are probably being devoted to it, which aren't sufficient.

360
00:49:33,120 --> 00:49:49,640
And you certainly wouldn't continue keeping it secret for the public. You would take precisely the opposite approach. So what's the consequences for science? What's the kind of consequences for understanding? Well, the consequences are terrible because you're not engaging in a collective process of discovery, research, debate, deliberation, vetting, all the things you need to do to keep it secret for the public.

361
00:50:03,120 --> 00:50:25,560
Arrive in new ideas and new truths. So to go back to your question, is it over compartmentalization? Is it over classification that's a problem? Yes, but it's also, it's not just the social process, the bureaucratic process. It's a kind of collective, psychological. It can cover up something for themselves.

362
00:50:25,800 --> 00:50:39,360
Gentlemen, the implications of this and that say we discover something truly profound and truly extraordinary, a non-human intelligence in whatever form that may be. What do we do?

363
00:50:39,360 --> 00:51:09,320
Well, first, I look at it this way. How many movies do we see on TV or series do we see on TV about a post-apocalyptic world? Humans seem married to this notion of something around the corner that's going to be a disaster. Well, I would look at these NHIs or whatever it is that this stuff might represent as hope, right? Or at least as a vision of a possibility that you can get past whatever that inflection point is in society.

364
00:51:09,360 --> 00:51:39,360
That might lead you to disaster. I mean, maybe the road to hope is through disaster. I don't know. But I think that's the first place that I start. The second is the very fact that whatever this is seems willing, at least at a distance, to let itself be seen is some kind of an indication that, I mean, people say, well, why don't they land on the White House lawn? Well, why do they need to, first of all? Second, we might be at one level beneath

365
00:51:39,360 --> 00:52:09,360
their notice. Third, the medium is the message that the fact that they're being seen is a message to individuals to say, well, can you see what's in front of you for what it is? In some ways, it's like the mirror test that we have with animals to determine intelligence. You know, can you see them in the mirror that what you're looking at is yourself? Not that you just need to ignore it because it doesn't bark back at you, but that it is actually you. And so, and another

366
00:52:09,360 --> 00:52:39,360
level, it's what a scientist would call data off the curve. You know, discoveries are not made by drawing a line and plotting dots along the line and saying, well, look, all the dots fit the line. It's when the point falls off the curve and it doesn't fit the line. That's where discovery is made. That's where the Nobel Prize winners all come from, is looking at the data off the curve. So I think what we're seeing is data off the curve. So in a way, and again, I challenge the skeptics, I call this an intelligence test. Can you see

367
00:52:39,360 --> 00:53:09,360
the data for what it is and not dismiss it using previous biases? So I think what we're seeing here from the NHI perspective is you have to ask them the question, okay, well, what is it that is so advanced that might even worry about us? Why would it worry about us? That's a whole set of questions that we could follow up on. The second might be, well, where did it come from? Did it come from another star? From, you know, did it come from some

368
00:53:09,360 --> 00:53:39,360
other form of or level of reality that we don't understand? And before we, I mean, obviously, I don't want to go down that rabbit hole. But again, many of your listeners are probably of a religious inclination. Where is heaven and hell? Is that another dimension? So if you're willing to believe in God and other places, like heaven and hell, then you already believe in other dimensions. So if there are things that can live in other dimensions, then maybe that's where they come from. I'm not saying that's what it is. I'm just speculating wildly. So

369
00:53:39,360 --> 00:54:09,360
and then there's the idea that maybe it's something that has been here all along. It came from perhaps another star long ago. And there was a scientist from the 1950s, 60s von Neumann who had an idea and eventually became known as the von Neumann probe idea. And the notion being that even if you came from a star on the other side of the galaxy, given about a billion years, you could even by conventional means, get all the way here simply to Earth,

370
00:54:09,360 --> 00:54:24,720
not that you knew you wanted to come to Earth. You just make a rock, make an object that goes to another place, makes more copies of yourself, sends out 100 copies of yourself to the next nearby stars, etc. And in very short order, in this case, about a billion years, you could be everywhere.

371
00:54:24,720 --> 00:54:54,720
And you just you didn't travel, but your intellectual progeny through, let's say, some kind of AI, artificial intelligence traveled. Now people say, oh, AI, what could that be? Well, we're using it today. Look at chat GPT, right? And all of its near cousins made by half a dozen. I mean, there's a trillion dollar industry starting up right in front of us that probably in a mat. Look at what it's done in only two years. Imagine what it would be in 100 years. So what we could do,

372
00:54:54,720 --> 00:55:14,720
we could be seeing as somebody else's chat GPT sent to us via a von Neumann probe approach. So I don't think humans are accustomed to thinking and the kinds of timeframes that evolution happens in. All of evolution that created us happened in basically about in less than a billion years.

373
00:55:14,720 --> 00:55:37,720
So and the universe has been around for about 14 or 15 billion years, about 11 billion of that were capable of producing the kind of life that we know. So you could have hundreds or thousands or millions of civilizations out there, any one of which could have or would have adopted a von Neumann probe approach. I mean, why would they?

374
00:55:37,720 --> 00:55:54,720
Well, I'm part of a company put together by Avi Loeb, astronomer at Harvard called the Copernicus Corporation, peopled with extremely high level credentials, other professors at Harvard, et cetera, people from NASA, et cetera, all helping.

375
00:55:54,720 --> 00:56:13,720
And what are we doing? Well, one thing we're doing is we're going to look for life on Mars. The other thing we're doing is we're going to build the first human von Neumann probe and send it out into the galaxy. So maybe a billion years from now, somebody with 10 tentacles will be having the same conversation wondering about what it is that's flying around in their skies. And they could have traced it all the way back to us.

376
00:56:14,720 --> 00:56:33,720
The scary thing about those kinds of ideas, though, is that number one, it collapses the Fermi paradox to a single solution. The zoo hypothesis. In other words, if you've got technology like that in your star system, an AI, you know, this is you are not in control.

377
00:56:34,720 --> 00:56:58,720
You are not in control even by virtue of its technology, just just by virtue of its technology. And it calls the shots even if it's totally altruistic or even uninterested in you. Problem is, you can have errors over time. And you can end up with a situation where you got a billion year old von Neumann probe that isn't quite right in the head anymore.

378
00:56:58,720 --> 00:57:17,720
And its original programming, its original programming is corrupted. And it's printing out biology and technology and all that with no real purpose anymore, other than just doing whatever it thinks it's supposed to do. And those those solutions get terrifying.

379
00:57:17,720 --> 00:57:20,720
It sounds like you've got a whole host of science fiction stories you could be writing.

380
00:57:21,720 --> 00:57:43,720
Or or a script. Yes, well, of course, it's me. It's me. That's what I started out as was a science fiction author. But no, I think you're I think you're right. But I mean, it's we always try to apply a human level logic and thinking to something which is inherently and the term non human, you know, covers it.

381
00:57:43,720 --> 00:57:55,720
But the logic is just it is is not what we should not anthropomorphize it. And so that's always the problem. We keep we keep trying to fit it into our logic structures.

382
00:57:55,720 --> 00:58:04,720
And again, this is the reason for a place like the soul foundation. And it's not as if these ideas haven't been played out in science fiction for decades.

383
00:58:04,720 --> 00:58:33,720
I mean, I've my bread and butter reading as a kid has been was was all of that. So it's all been played out before in many different ways and beautiful and fun ways. But now some of those need to be brought to the public at large and to, I think, policymakers at large to say, let's talk about this in a way that allows us to use it or to at least frame a defense against the shock of it.

384
00:58:34,720 --> 00:58:48,720
I mean, it's it's it's not that I mean, look, it could probably in the blink of an eye, wipe us off the face of the earth, drop a rock on us, like happened to the dinosaurs.

385
00:58:48,720 --> 00:58:56,720
And that would be it. And it wouldn't take much. But it hasn't. So at that level, I'm not worried about its intent, whatever it might be, because it could have.

386
00:58:56,720 --> 00:59:12,720
I mean, yes, we are under its under its thumb, let's say, if that's how you want to think about it. But that doesn't worry me because, you know, it's not anything that I can affect. And again, I always try to look for the hopeful opportunity here.

387
00:59:12,720 --> 00:59:28,720
So I look at what we see these vehicles seem to manifest in terms of their capabilities. And I say, I want to do that. I want to give other humans the chance to have an opportunity to use that.

388
00:59:28,720 --> 00:59:40,720
So how do I structure my arguments to convince other people not what it is or what its intent might be, but how can I take advantage of it? And we do that as scientists all the time.

389
00:59:40,720 --> 00:59:55,720
I mean, just look at the biology that we know exists in our bodies and what we know our bodies are capable of. And it's a mechanism that is more complex than any instrument or object that these things might represent.

390
00:59:55,720 --> 01:00:02,720
And yet there's extraordinary opportunity just understanding how the human body works for human health or human capabilities.

391
01:00:02,720 --> 01:00:13,720
So the same tools that I bring to bear on my science or other scientists bring to bear biology or the natural world is the same kind of thing that I'm just saying.

392
01:00:14,720 --> 01:00:25,720
Maybe we should spend some time applying to these, whatever these NHIs are. Frankly, I think what we're dealing with is not the original creator of the vehicles.

393
01:00:25,720 --> 01:00:38,720
I think it's, you know, just again, speculating. I think it's something made in a way to interact with us. I mean, I've used this example of if you had an erase of intelligent ants at the bottom of your garden, how do you interact with it?

394
01:00:38,720 --> 01:00:44,720
How do you tell it about TikTok? Right? What's lost in translation is if you try to interact with it.

395
01:00:44,720 --> 01:00:51,720
Probably the best you could do is dangle something that kind of looked like an ant in front of it and dance it around and say, hey, look, there's somebody else here.

396
01:00:51,720 --> 01:00:58,720
Right. But anything you might try to tell it about what your original intent might be is impossible to convey.

397
01:00:59,720 --> 01:01:03,720
So again, the medium is the message.

398
01:01:03,720 --> 01:01:15,720
Gary, do you think as a scientist projecting yourself forward in the future with your thinking, does it make some sort of logical sense for, you know, again, we're talking about von Neumann probes and things like that.

399
01:01:15,720 --> 01:01:21,720
But it just just sort of seed technology and say, well, look, you've hit splitting the atom.

400
01:01:22,720 --> 01:01:36,720
We saw it. And now what we're going to do is seed a little bit of technology so that you learn in the right direction and manage your society better based on what you're finding on what we give you crashes or whatever.

401
01:01:36,720 --> 01:01:41,720
Maybe that's it. Does that make sense as a scientist? Might you do it that way?

402
01:01:41,720 --> 01:01:49,720
Yes, that's if you remember back when I was talking about Carl Nels amendments and the whole well, the state secret goes into the public openly.

403
01:01:49,720 --> 01:01:55,720
The fight is always going to be not to release stuff is to have some kind of committee or some.

404
01:01:55,720 --> 01:02:08,720
I mean, I hate saying the government is the solution because it's I've learned again and again, they're not have some sort of public private commission that says, well, here are things that we hope are not dangerous.

405
01:02:08,720 --> 01:02:22,720
But that if brought to public understanding and bringing the right scientists in with investment would engage the investment community because they would see the obvious benefit, give them an opportunity to license the intellectual property.

406
01:02:22,720 --> 01:02:33,720
They might come from it, but then also bring in the right kinds of scientists who in other realms would not be able to get security clearance because of their, let's say behavior, drug use or what have you.

407
01:02:33,720 --> 01:02:38,720
That would then allow them to bring their intellectual merit to the table.

408
01:02:38,720 --> 01:02:47,720
So, yes, I think seeding that. But do I trust Lockheed to do that? No, I mean, I know how big corporations work. I work with pharma.

409
01:02:47,720 --> 01:02:56,720
Thousands of great ideas literally get buried or shut down because somebody decided the program needs to move in a different direction.

410
01:02:56,720 --> 01:02:59,720
Some pencil pusher decided not a scientist.

411
01:02:59,720 --> 01:03:18,720
And so there needs to be a more formalized way to comb through what has been understood about how these vehicles operate, what might be understood and then saying, OK, here's something that maybe we could bring and to I'll go walk it down.

412
01:03:19,720 --> 01:03:27,720
I'll go walk it up and down Sand Hill Road where all the venture capital is here in the Bay Area, and I'll see who wants to put money down.

413
01:03:27,720 --> 01:03:33,720
I bet I would walk out with a pocket full of opportunities. I know we already doing it.

414
01:03:33,720 --> 01:03:39,720
I mean, I've already got I've already got a laundry list of VCs waiting to put money in to this.

415
01:03:39,720 --> 01:03:48,720
I mean, they're all excited because VCs venture community, which has driven the U.S. economy for the last 20 years.

416
01:03:48,720 --> 01:03:56,720
They are risk takers and they are willing to put money into something that has opportunity.

417
01:03:56,720 --> 01:04:04,720
So I think we have an ignition opportunity here for restarting the U.S. economy in a whole new set of directions.

418
01:04:04,720 --> 01:04:07,720
And I'd rather see it happen here in the United States than elsewhere.

419
01:04:07,720 --> 01:04:15,720
But I still think I still think, though, that what happens here can benefit the rest of the planet as well.

420
01:04:15,720 --> 01:04:21,720
Technology, you know, it proliferates and everything, you know, gets it improves overall.

421
01:04:21,720 --> 01:04:25,720
Gary, I know you have a hard out and thank you for joining us.

422
01:04:25,720 --> 01:04:32,720
And one of these days, I would love to get together with you and just have a conversation about cancer research and the lost opportunities of big pharma.

423
01:04:33,720 --> 01:04:37,720
Oh, sure. Happy to do so. Well, thank you guys very much.

424
01:04:37,720 --> 01:04:43,720
Great conversation. And I look forward to more as the Seoul Foundation's activities continue on.

425
01:04:43,720 --> 01:04:50,720
And maybe we learn more about whatever this is, but it's certainly worth looking into.

426
01:04:50,720 --> 01:04:57,720
Event Horizon and my channel are now available as a podcast on Apple podcasts, Spotify and YouTube memberships,

427
01:04:57,720 --> 01:05:01,720
early ad free episodes, bonus episodes and sleep focused content.

428
01:05:01,720 --> 01:05:06,720
Sign up now by clicking the links below to your platform of choice.

429
01:07:57,720 --> 01:08:00,720
Thank you.

